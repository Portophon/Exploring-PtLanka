{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Packages</a></span></li><li><span><a href=\"#Barplot-config\" data-toc-modified-id=\"Barplot-config-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Barplot config</a></span></li><li><span><a href=\"#Load-data-set\" data-toc-modified-id=\"Load-data-set-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Load data set</a></span></li></ul></li><li><span><a href=\"#IPA\" data-toc-modified-id=\"IPA-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>IPA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stats\" data-toc-modified-id=\"Stats-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Stats</a></span></li></ul></li><li><span><a href=\"#Spelling\" data-toc-modified-id=\"Spelling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Spelling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Words-with-[p]-,-[m]-,-[lh]-and-[nh]\" data-toc-modified-id=\"Words-with-[p]-,-[m]-,-[lh]-and-[nh]-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Words with [p] , [m] , [lh] and [nh]</a></span></li><li><span><a href=\"#Free-diphtong-words\" data-toc-modified-id=\"Free-diphtong-words-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Free diphtong words</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-syllable-annotated-datasets\" data-toc-modified-id=\"Load-syllable-annotated-datasets-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Load syllable annotated datasets</a></span></li></ul></li><li><span><a href=\"#[lh]-and-[nh]\" data-toc-modified-id=\"[lh]-and-[nh]-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>[lh] and [nh]</a></span><ul class=\"toc-item\"><li><span><a href=\"#vowels\" data-toc-modified-id=\"vowels-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>vowels</a></span></li><li><span><a href=\"#contiguous-left\" data-toc-modified-id=\"contiguous-left-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>contiguous left</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-syllable-annotated-datasets\" data-toc-modified-id=\"Load-syllable-annotated-datasets-2.3.2.1\"><span class=\"toc-item-num\">2.3.2.1&nbsp;&nbsp;</span>Load syllable annotated datasets</a></span></li></ul></li><li><span><a href=\"#position\" data-toc-modified-id=\"position-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>position</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-syllable-annotated-datasets\" data-toc-modified-id=\"Load-syllable-annotated-datasets-2.3.3.1\"><span class=\"toc-item-num\">2.3.3.1&nbsp;&nbsp;</span>Load syllable annotated datasets</a></span></li></ul></li></ul></li><li><span><a href=\"#double-position\" data-toc-modified-id=\"double-position-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>double position</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CARLOS~1\\AppData\\Local\\Temp/ipykernel_3184/295557243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patches as mpatches\n",
    "import squarify \n",
    "\n",
    "import urllib\n",
    "import ast\n",
    "from collections import Counter\n",
    "from ast import literal_eval\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplot config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)\n",
    "\n",
    "def show_values_on_bars_v(axs):\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,y1 ,y2))\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() - 0.01 + p.get_width() / 2.\n",
    "            _y = p.get_y() + p.get_height() * 1.02\n",
    "            value = '{:.3f}%'.format(p.get_height()*100)\n",
    "            ax.text(_x, _y+0.3, value, ha=\"center\") \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "        \n",
    "def show_values_on_bars_h(axs):\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,y1 ,y2))\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() #+ 0.4\n",
    "            _y = p.get_y() + p.get_height()\n",
    "            value = '{:.3f}%'.format(p.get_width()*100)\n",
    "            ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "        \n",
    "\n",
    "def show_values_on_bars_reg_v(axs):\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,y1 ,y2 + 8))\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() - 0.01 + p.get_width() / 2.\n",
    "            _y = p.get_y() + p.get_height() * 1.02\n",
    "            value = '{:.0f}'.format(p.get_height())\n",
    "            ax.text(_x, _y+0.3, value, ha=\"center\") \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "        \n",
    "def show_values_on_bars_reg_h(axs):\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2+8,y1 ,y2))\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() + 0.4\n",
    "            _y = p.get_y() + p.get_height()\n",
    "            value = '{:.0f}'.format(p.get_width())\n",
    "            ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spelling</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ejʃˈseɾtu, ejˈʃeɾtu]</td>\n",
       "      <td>excerto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[pɨ.ˈlu.ʃɨ]</td>\n",
       "      <td>peluche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[kõ.tɾi.bu.i.ˈsɐ̃w̃]</td>\n",
       "      <td>contribuição</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[aɫ.ˈɡɐ̃j̃]</td>\n",
       "      <td>alguém</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ˈkawʃ]</td>\n",
       "      <td>caos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12369</th>\n",
       "      <td>[ku.ˈpi.ɔ.zus]</td>\n",
       "      <td>copiosos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12370</th>\n",
       "      <td>[ku.ˈpi.ɔ.zas]</td>\n",
       "      <td>copiosas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12371</th>\n",
       "      <td>[ku.ˈpi.ɔ.za]</td>\n",
       "      <td>copiosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12372</th>\n",
       "      <td>[ʀi.ɐ.ˈliʃ.ti.co]</td>\n",
       "      <td>realístico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12373</th>\n",
       "      <td>[]</td>\n",
       "      <td>dutoviário</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12374 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    spelling          word\n",
       "0      [ejʃˈseɾtu, ejˈʃeɾtu]       excerto\n",
       "1                [pɨ.ˈlu.ʃɨ]       peluche\n",
       "2       [kõ.tɾi.bu.i.ˈsɐ̃w̃]  contribuição\n",
       "3                [aɫ.ˈɡɐ̃j̃]        alguém\n",
       "4                    [ˈkawʃ]          caos\n",
       "...                      ...           ...\n",
       "12369         [ku.ˈpi.ɔ.zus]      copiosos\n",
       "12370         [ku.ˈpi.ɔ.zas]      copiosas\n",
       "12371          [ku.ˈpi.ɔ.za]       copiosa\n",
       "12372      [ʀi.ɐ.ˈliʃ.ti.co]    realístico\n",
       "12373                     []    dutoviário\n",
       "\n",
       "[12374 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 54e96471d9886f34dc4844ec8e57adde5a281bc3
   "source": [
    "word_df = pd.read_csv('wikcionario_IPA.csv') \n",
    "word_df[\"spelling\"] = word_df[\"spelling\"].apply(eval)\n",
    "word_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ejʃˈseɾtu', 'ejˈʃeɾtu'],\n",
       " ['pɨ.ˈlu.ʃɨ'],\n",
       " ['kõ.tɾi.bu.i.ˈsɐ̃w̃'],\n",
       " ['aɫ.ˈɡɐ̃j̃'],\n",
       " ['ˈkawʃ'],\n",
       " ['ˈaɫ.ɡu'],\n",
       " ['ɐ.nɐɾ.ˈki.ɐ'],\n",
       " ['sɨ.ˈlɐj.ɾu'],\n",
       " ['kɐ.ˈɾi.ɔ.kɐ'],\n",
       " ['gɾa.tiʃ']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 54e96471d9886f34dc4844ec8e57adde5a281bc3
   "source": [
    "pt_entries_IPA = list(word_df[\"spelling\"])\n",
    "pt_entries_IPA[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' e j ʃ ˈ s e ɾ t u ',\n",
       " ' e j ˈ ʃ e ɾ t u ',\n",
       " ' p ɨ . ˈ l u . ʃ ɨ ',\n",
       " ' k õ . t ɾ i . b u . i . ˈ s ɐ ̃ w ̃ ',\n",
       " ' a ɫ . ˈ ɡ ɐ ̃ j ̃ ',\n",
       " ' ˈ k a w ʃ ',\n",
       " ' ˈ a ɫ . ɡ u ',\n",
       " ' ɐ . n ɐ ɾ . ˈ k i . ɐ ',\n",
       " ' s ɨ . ˈ l ɐ j . ɾ u ',\n",
       " ' k ɐ . ˈ ɾ i . ɔ . k ɐ ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 54e96471d9886f34dc4844ec8e57adde5a281bc3
   "source": [
    "pt_entries_IPA = list(word_df[\"spelling\"])\n",
    "\n",
    "pt_entries_IPA = [item for sublist in pt_entries_IPA for item in sublist]\n",
    "pt_entries_IPA = [\" \".join(list(str(i))) for i in pt_entries_IPA]\n",
    "pt_entries_IPA = [re.sub(\"^\", \" \", i) for i in pt_entries_IPA]\n",
    "pt_entries_IPA = [re.sub(\"$\", \" \", i) for i in pt_entries_IPA]\n",
    "pt_entries_IPA = [re.sub(\"g ʷ\", \"gʷ\", i) for i in pt_entries_IPA]\n",
    "pt_entries_IPA = [re.sub(\"k ʷ\", \"kʷ\", i) for i in pt_entries_IPA]\n",
    "pt_entries_IPA[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_split = [i.split(\" \") for i in pt_entries_IPA]\n",
    "word_list_split = [item for sublist in word_list_split for item in sublist]\n",
    "word_list_split = [x for x in word_list_split if x]\n",
    "word_list_split[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPA</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>30050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ˈ</td>\n",
       "      <td>12318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ɐ</td>\n",
       "      <td>10374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ɾ</td>\n",
       "      <td>8132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u</td>\n",
       "      <td>7921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ô</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ŋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>é</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IPA  count\n",
       "0    .  30050\n",
       "1    ˈ  12318\n",
       "2    ɐ  10374\n",
       "3    ɾ   8132\n",
       "4    u   7921\n",
       "..  ..    ...\n",
       "62   ô      1\n",
       "63   ŋ      1\n",
       "64   S      1\n",
       "65   _      1\n",
       "66   é      1\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 54e96471d9886f34dc4844ec8e57adde5a281bc3
   "source": [
    "counts = Counter(word_list_split)\n",
    "df = pd.DataFrame.from_dict(counts, orient='index').reset_index()\n",
    "df.columns = [\"IPA\", \"count\"]\n",
    "df = df.sort_values(by=[\"count\"],ascending=False).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPA</th>\n",
       "      <th>count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>30050</td>\n",
       "      <td>12160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ˈ</td>\n",
       "      <td>12318</td>\n",
       "      <td>12313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ɐ</td>\n",
       "      <td>10374</td>\n",
       "      <td>7254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ɾ</td>\n",
       "      <td>8132</td>\n",
       "      <td>6717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u</td>\n",
       "      <td>7921</td>\n",
       "      <td>6375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ô</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ŋ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>é</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IPA  count  word_count\n",
       "0    .  30050       12160\n",
       "1    ˈ  12318       12313\n",
       "2    ɐ  10374        7254\n",
       "3    ɾ   8132        6717\n",
       "4    u   7921        6375\n",
       "..  ..    ...         ...\n",
       "62   ô      1           1\n",
       "63   ŋ      1           1\n",
       "64   S      1           1\n",
       "65   _      1           1\n",
       "66   é      1           1\n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 54e96471d9886f34dc4844ec8e57adde5a281bc3
   "source": [
    "IPA_list = list(df[\"IPA\"])\n",
    "in_word_list = []\n",
    "for word in IPA_list:\n",
    "    word_search = \" \"+ word + \" \"\n",
    "    matches = len([match for match in pt_entries_IPA if word_search in match])\n",
    "    in_word_list.append(matches)\n",
    "df[\"word_count\"] = in_word_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"wikcionario_IPA_stats.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words with [p] , [m] , [lh] and [nh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m_nh_lh_dipth_stats_list = []\n",
    "p_m_nh_lh_dipth_stats_list.append([\"word_all\",len(word_df)])\n",
    "print(\"total unique words: \" + str(len(word_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spelling</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[pɨ.ˈlu.ʃɨ]</td>\n",
       "      <td>peluche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[puɾ.tu.ˈɡeʃ]</td>\n",
       "      <td>português</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[ʒɐ.pu.ˈneʃ]</td>\n",
       "      <td>japonês</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[tɾi.pli.ˈkaɾ]</td>\n",
       "      <td>triplicar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[kʷɐ.dɾu.pli.ˈkaɾ]</td>\n",
       "      <td>quadruplicar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12360</th>\n",
       "      <td>[iʃ.pɐ.ʀi.ˈɲaɾ]</td>\n",
       "      <td>esparrinhar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12362</th>\n",
       "      <td>[puɾ.ˈtẽ.tu]</td>\n",
       "      <td>portento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12369</th>\n",
       "      <td>[ku.ˈpi.ɔ.zus]</td>\n",
       "      <td>copiosos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12370</th>\n",
       "      <td>[ku.ˈpi.ɔ.zas]</td>\n",
       "      <td>copiosas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12371</th>\n",
       "      <td>[ku.ˈpi.ɔ.za]</td>\n",
       "      <td>copiosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 spelling          word\n",
       "1             [pɨ.ˈlu.ʃɨ]       peluche\n",
       "16          [puɾ.tu.ˈɡeʃ]     português\n",
       "28           [ʒɐ.pu.ˈneʃ]       japonês\n",
       "35         [tɾi.pli.ˈkaɾ]     triplicar\n",
       "36     [kʷɐ.dɾu.pli.ˈkaɾ]  quadruplicar\n",
       "...                   ...           ...\n",
       "12360     [iʃ.pɐ.ʀi.ˈɲaɾ]   esparrinhar\n",
       "12362        [puɾ.ˈtẽ.tu]      portento\n",
       "12369      [ku.ˈpi.ɔ.zus]      copiosos\n",
       "12370      [ku.ˈpi.ɔ.zas]      copiosas\n",
       "12371       [ku.ˈpi.ɔ.za]       copiosa\n",
       "\n",
       "[2400 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 54e96471d9886f34dc4844ec8e57adde5a281bc3
   "source": [
    "word_p = word_df[word_df[\"word\"].str.contains(\"p\")]\n",
    "p_m_nh_lh_dipth_stats_list.append([\"word_p\",len(word_p)])\n",
    "word_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spelling</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[i.ti.mu.lu.ˈʒi.ɐ]</td>\n",
       "      <td>etimologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[vi.ɛt.nɐ.ˈmi.tɐ]</td>\n",
       "      <td>vietnamita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[ˈɛ.ti.mu]</td>\n",
       "      <td>étimo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[ɔ.ˈmɔ.lu.ɡu]</td>\n",
       "      <td>homólogo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[mɨ.di.ɛ.ˈvaɫ]</td>\n",
       "      <td>medieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12348</th>\n",
       "      <td>[ɐ.ɡɾɐ.vɐ.ˈmẽ.tu]</td>\n",
       "      <td>agravamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12350</th>\n",
       "      <td>[i.mu.dɨ.ˈɾa.du]</td>\n",
       "      <td>imoderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12354</th>\n",
       "      <td>[pɾi.e.mi.ˈnẽ.si.ɐ]</td>\n",
       "      <td>preeminência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12361</th>\n",
       "      <td>[muʃ.kɐ.ˈtɛɫ]</td>\n",
       "      <td>moscatel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12367</th>\n",
       "      <td>[kɐ.mɐ.ɾɐ.ʒi.ˈbẽ.sɨ]</td>\n",
       "      <td>camaragibense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2364 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   spelling           word\n",
       "19       [i.ti.mu.lu.ˈʒi.ɐ]     etimologia\n",
       "34        [vi.ɛt.nɐ.ˈmi.tɐ]     vietnamita\n",
       "42               [ˈɛ.ti.mu]          étimo\n",
       "44            [ɔ.ˈmɔ.lu.ɡu]       homólogo\n",
       "45           [mɨ.di.ɛ.ˈvaɫ]       medieval\n",
       "...                     ...            ...\n",
       "12348     [ɐ.ɡɾɐ.vɐ.ˈmẽ.tu]    agravamento\n",
       "12350      [i.mu.dɨ.ˈɾa.du]      imoderado\n",
       "12354   [pɾi.e.mi.ˈnẽ.si.ɐ]   preeminência\n",
       "12361         [muʃ.kɐ.ˈtɛɫ]       moscatel\n",
       "12367  [kɐ.mɐ.ɾɐ.ʒi.ˈbẽ.sɨ]  camaragibense\n",
       "\n",
       "[2364 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 54e96471d9886f34dc4844ec8e57adde5a281bc3
   "source": [
    "m_list = \"m[aáàâãeéèêiíìoóòôõuúù]\"\n",
    "word_m = word_df[word_df[\"word\"].str.contains(m_list)]\n",
    "p_m_nh_lh_dipth_stats_list.append([\"word_m\",len(word_m)])\n",
    "word_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lh = word_df[word_df[\"word\"].str.contains(\"lh\")]\n",
    "p_m_nh_lh_dipth_stats_list.append([\"word_lh\",len(word_lh)])\n",
    "word_lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spelling</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[ɐ.ˈbɾu.ɲu]</td>\n",
       "      <td>abrunho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>[kɐ.ˈɲɐ̃w̃]</td>\n",
       "      <td>canhão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>[su.ˈɲaɾ]</td>\n",
       "      <td>sonhar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>[kɐʃ.ˈtɐ.ɲɐ]</td>\n",
       "      <td>castanha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>[ẽ.di.ɲɐj.ˈɾa.du]</td>\n",
       "      <td>endinheirado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12175</th>\n",
       "      <td>[ɡɐ.ɲɐ.ˈdoɾ]</td>\n",
       "      <td>ganhador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12190</th>\n",
       "      <td>[kɔ.ˈvi.ɲɐ]</td>\n",
       "      <td>covinha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12212</th>\n",
       "      <td>[ko.mɨ.ˈzi.ɲu]</td>\n",
       "      <td>comezinho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12336</th>\n",
       "      <td>[fɐ.ɾi.ˈɲẽ.tu]</td>\n",
       "      <td>farinhento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12360</th>\n",
       "      <td>[iʃ.pɐ.ʀi.ˈɲaɾ]</td>\n",
       "      <td>esparrinhar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                spelling          word\n",
       "56           [ɐ.ˈbɾu.ɲu]       abrunho\n",
       "117          [kɐ.ˈɲɐ̃w̃]        canhão\n",
       "212            [su.ˈɲaɾ]        sonhar\n",
       "239         [kɐʃ.ˈtɐ.ɲɐ]      castanha\n",
       "414    [ẽ.di.ɲɐj.ˈɾa.du]  endinheirado\n",
       "...                  ...           ...\n",
       "12175       [ɡɐ.ɲɐ.ˈdoɾ]      ganhador\n",
       "12190        [kɔ.ˈvi.ɲɐ]       covinha\n",
       "12212     [ko.mɨ.ˈzi.ɲu]     comezinho\n",
       "12336     [fɐ.ɾi.ˈɲẽ.tu]    farinhento\n",
       "12360    [iʃ.pɐ.ʀi.ˈɲaɾ]   esparrinhar\n",
       "\n",
       "[207 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 54e96471d9886f34dc4844ec8e57adde5a281bc3
   "source": [
    "word_nh = word_df[word_df[\"word\"].str.contains(\"nh\")]\n",
    "p_m_nh_lh_dipth_stats_list.append([\"word_nh\",len(word_nh)])\n",
    "word_nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m_nh_lh_dipth_stats = pd.DataFrame(p_m_nh_lh_dipth_stats_list, columns=[\"item\",\"length\"])\n",
    "p_m_nh_lh_dipth_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_total_words_length = p_m_nh_lh_dipth_stats[\"length\"].max()\n",
    "\n",
    "p_m_nh_lh_dipth_stats[\"length\"] = p_m_nh_lh_dipth_stats[\"length\"]/max_total_words_length\n",
    "p_m_nh_lh_dipth_stats[\"length\"] = p_m_nh_lh_dipth_stats[\"length\"].round(5)\n",
    "p_m_nh_lh_dipth_stats.drop(index=p_m_nh_lh_dipth_stats.index[0], axis=0, inplace=True)\n",
    "p_m_nh_lh_dipth_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_colors = {\n",
    "    #'word_all': '#dddddd',\n",
    "    'word_p': '#aaaaaa',\n",
    "    'word_m': '#aaaaaa',\n",
    "    'word_lh': '#5975a4',\n",
    "    'word_lh_clitic': '#5975a4',\n",
    "    'word_nh': '#cc8963',\n",
    "    'word_nh_diminutive': '#cc8963'\n",
    "}\n",
    "\n",
    "all_colors = list(all_colors.values())\n",
    "sns.set_palette(sns.color_palette(all_colors))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(x=\"length\", y=\"item\" , data=p_m_nh_lh_dipth_stats)\n",
    "ax.xaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "ax.set(xlim=(0, 0.3))\n",
    "show_values_on_bars_h(ax)\n",
    "fig.set_size_inches(3.5, 0.9)\n",
    "ax.set(xlabel=\"Count\", ylabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"word_IPA_wikcionario_lh_nh.xlsx\", \n",
    "                        engine='xlsxwriter', \n",
    "                        options={'encoding':'utf-8'}) \n",
    "\n",
    "word_lh.to_excel(writer, index=False, sheet_name='word_lh')\n",
    "word_nh.to_excel(writer, index=False, sheet_name='word_nh')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free diphtong words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipht_free_ai = word_df[word_df[\"word\"].str.contains(\"ai\")]\n",
    "dipht_free_ei = word_df[word_df[\"word\"].str.contains(\"ei|éi\")]\n",
    "dipht_free_oi = word_df[word_df[\"word\"].str.contains(\"oi|ói\")]\n",
    "dipht_free_ui = word_df[word_df[\"word\"].str.contains(\"ui\")]\n",
    "dipht_free_ui = dipht_free_ui[~dipht_free_ui[\"word\"].str.contains(\"gui|qui\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"word_IPA_wikcionario_dipht_free.xlsx\", \n",
    "                        engine='xlsxwriter', \n",
    "                        options={'encoding':'utf-8'}) \n",
    "\n",
    "dipht_free_ai.to_excel(writer, index=False, sheet_name='dipht_free_ai')\n",
    "dipht_free_ei.to_excel(writer, index=False, sheet_name='dipht_free_ei')\n",
    "dipht_free_oi.to_excel(writer, index=False, sheet_name='dipht_free_oi')\n",
    "dipht_free_ui.to_excel(writer, index=False, sheet_name='dipht_free_ui')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load syllable annotated datasets\n",
    "Syllabifier from https://portulanclarin.net/workbench/lx-syllabifier/\n",
    "\n",
    "Syllabifier included in new column of word_dicio_aberto_dipht_free.xlsx file copy sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipht_free_list = []\n",
    "dipht_free_ai = pd.read_excel(\"word_IPA_wikcionario_dipht_free_with_syllabification.xlsx\", sheet_name=\"dipht_free_ai\")\n",
    "dipht_free_ai = dipht_free_ai[dipht_free_ai[\"Syllabifier\"].str.contains(\"ai•|ai$\")]\n",
    "dipht_free_ai = len(dipht_free_ai)\n",
    "\n",
    "dipht_free_ei = pd.read_excel(\"word_IPA_wikcionario_dipht_free_with_syllabification.xlsx\", sheet_name=\"dipht_free_ei\")\n",
    "dipht_free_ei = dipht_free_ei[dipht_free_ei[\"Syllabifier\"].str.contains(\"ei•|ei$\")]\n",
    "dipht_free_ei = len(dipht_free_ei)\n",
    "\n",
    "dipht_free_oi = pd.read_excel(\"word_IPA_wikcionario_dipht_free_with_syllabification.xlsx\", sheet_name=\"dipht_free_oi\")\n",
    "dipht_free_oi = dipht_free_oi[dipht_free_oi[\"Syllabifier\"].str.contains(\"oi•|oi$\")]\n",
    "\n",
    "dipht_free_ou_or_oi = dipht_free_oi.copy()\n",
    "dipht_free_ou_or_oi[\"word\"] = dipht_free_oi[\"word\"].replace(to_replace=r'oi', value='ou', regex=True)\n",
    "dipht_free_ou = word_df[word_df[\"word\"].str.contains(\"ou\")]\n",
    "dipht_free_ou_or_oi = dipht_free_ou_or_oi[[\"word\",\"Syllabifier\"]]\n",
    "dipht_free_ou_or_oi = pd.merge(dipht_free_ou, dipht_free_ou_or_oi, how = \"inner\", indicator = False)\n",
    "dipht_free_ou_or_oi = len(dipht_free_ou_or_oi)\n",
    "dipht_free_oi = len(dipht_free_oi)\n",
    "\n",
    "dipht_free_ui = pd.read_excel(\"word_IPA_wikcionario_dipht_free_with_syllabification.xlsx\", sheet_name=\"dipht_free_ui\")\n",
    "dipht_free_ui = dipht_free_ui[dipht_free_ui[\"Syllabifier\"].str.contains(\"ui•|ui$\")]\n",
    "#dipht_free_ui = dipht_free_ui[~dipht_free_ui[\"word\"].str.contains(\"uim$|uir$\")]\n",
    "dipht_free_ui = len(dipht_free_ui)\n",
    "\n",
    "dipht_free_list.append([\"dipht_free_ai\",dipht_free_ai])\n",
    "dipht_free_list.append([\"dipht_free_ei\",dipht_free_ei])\n",
    "dipht_free_list.append([\"dipht_free_oi\",dipht_free_oi])\n",
    "dipht_free_list.append([\"dipht_free_ou_or_oi\",dipht_free_ou_or_oi])\n",
    "dipht_free_list.append([\"dipht_free_ui\",dipht_free_ui])\n",
    "\n",
    "dipht_free_df = pd.DataFrame(dipht_free_list, columns=[\"item\",\"length\"])\n",
    "dipht_free_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipht_free_df[\"length\"] = dipht_free_df[\"length\"]/max_total_words_length\n",
    "dipht_free_df[\"length\"] = dipht_free_df[\"length\"].round(5)\n",
    "dipht_free_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_m_nh_lh_dipth_stats = p_m_nh_lh_dipth_stats.append(dipht_free_df)\n",
    "p_m_nh_lh_dipth_stats = p_m_nh_lh_dipth_stats.reset_index(drop=True)\n",
    "p_m_nh_lh_dipth_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_colors = {\n",
    "    #'word_all': '#dddddd',\n",
    "    'word_p': '#aaaaaa',\n",
    "    'word_m': '#aaaaaa',\n",
    "    'word_lh': '#5975a4',\n",
    "    'word_nh': '#cc8963',\n",
    "    'diph_free_ai': '#e6cbcb',\n",
    "    'diph_free_ei': '#c49299',\n",
    "    #'i': '#9f8097',\n",
    "    'diph_free_oi': '#594772',\n",
    "    'diph_free_oi_or_ui': '#594772',\n",
    "    'diph_free_ui': '#21314e'\n",
    "}\n",
    "\n",
    "all_colors = list(all_colors.values())\n",
    "sns.set_palette(sns.color_palette(all_colors))\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(x=\"length\", y=\"item\", data=p_m_nh_lh_dipth_stats)\n",
    "ax.xaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "ax.set(xlim=(0, 0.3))\n",
    "show_values_on_bars_h(ax)\n",
    "fig.set_size_inches(5, 3.5)\n",
    "ax.set(xlabel=\"Count\", ylabel=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [lh] and [nh]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dipht_free_list = []\n",
    "dipht_free_list.append([\"a\",\"_i\",dipht_free_ai])\n",
    "dipht_free_list.append([\"e\",\"_i\",dipht_free_ei])\n",
    "dipht_free_list.append([\"i\",\"_i\",0])\n",
    "dipht_free_list.append([\"o\",\"_i\",dipht_free_oi])\n",
    "dipht_free_list.append([\"u\",\"_i\",dipht_free_ui])\n",
    "\n",
    "dipht_free_df = pd.DataFrame(dipht_free_list, columns=[\"vowel\",\"item\",\"length\"])\n",
    "dipht_free_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palatal_vowel_list = []\n",
    "\n",
    "left_a_lh = word_df[word_df[\"word\"].str.contains(\"alh|álh|àlh|âlh\")]\n",
    "palatal_vowel_list.append([\"a\",\"_lh\",len(left_a_lh)])\n",
    "left_e_lh = word_df[word_df[\"word\"].str.contains(\"elh|élh|èlh|êlh\")]\n",
    "palatal_vowel_list.append([\"e\",\"_lh\",len(left_e_lh)])\n",
    "left_i_lh = word_df[word_df[\"word\"].str.contains(\"ilh|ílh|ìlh\")]\n",
    "palatal_vowel_list.append([\"i\",\"_lh\",len(left_i_lh)])\n",
    "left_o_lh = word_df[word_df[\"word\"].str.contains(\"olh|ólh|òlh|ôlh\")]\n",
    "palatal_vowel_list.append([\"o\",\"_lh\",len(left_o_lh)])\n",
    "left_u_lh = word_df[word_df[\"word\"].str.contains(\"ulh|úlh|ùlh\")]\n",
    "palatal_vowel_list.append([\"u\",\"_lh\",len(left_u_lh)])\n",
    "\n",
    "left_a_nh = word_df[word_df[\"word\"].str.contains(\"anh|ánh|ành|ânh\")]\n",
    "palatal_vowel_list.append([\"a\",\"_nh\",len(left_a_nh)])\n",
    "left_e_nh = word_df[word_df[\"word\"].str.contains(\"enh|énh|ènh|ênh\")]\n",
    "palatal_vowel_list.append([\"e\",\"_nh\",len(left_e_nh)])\n",
    "left_i_nh = word_df[word_df[\"word\"].str.contains(\"inh|ính|ình\")]\n",
    "palatal_vowel_list.append([\"i\",\"_nh\",len(left_i_nh)])\n",
    "left_o_nh = word_df[word_df[\"word\"].str.contains(\"onh|ónh|ònh|ônh\")]\n",
    "palatal_vowel_list.append([\"o\",\"_nh\",len(left_o_nh)])\n",
    "left_u_nh = word_df[word_df[\"word\"].str.contains(\"unh|únh|ùnh\")]\n",
    "palatal_vowel_list.append([\"u\",\"_nh\",len(left_u_nh)])\n",
    "\n",
    "palatal_vowel_df = pd.DataFrame(palatal_vowel_list, columns=[\"vowel\",\"item\",\"length\"])\n",
    "\n",
    "palatal_vowel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_combo_df = pd.concat([dipht_free_df, palatal_vowel_df], axis= 0)\n",
    "vowel_combo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = vowel_combo_df.groupby(['vowel','item']).sum().unstack()\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df_count\n",
    "norm_df = (df_count)/(df_count.sum())*100\n",
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vowel_colors = {\n",
    "    'a': '#e6cbcb',\n",
    "    'e': '#c49299',\n",
    "    'i': '#9f8097',\n",
    "    'o': '#594772',\n",
    "    'u': '#21314e'\n",
    "}\n",
    "\n",
    "vowel_order = list(vowel_colors.keys())\n",
    "\n",
    "\n",
    "ax = norm_df.loc[reversed(vowel_order)].T.plot.bar(stacked=True,color = vowel_colors, figsize=(3,3), tick_label=['_i','_lh','_nh'])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(reversed(handles), reversed(labels),bbox_to_anchor=(1.0, 1.0))\n",
    "ax.set( xlabel=\"Items\")\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "ax.set_xticklabels(list(norm_df['length']),rotation=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "palatal_vowel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palatal_vowel_df[\"length\"] = palatal_vowel_df[\"length\"]/max_total_words_length\n",
    "palatal_vowel_df[\"length\"] = palatal_vowel_df[\"length\"].round(5)\n",
    "palatal_vowel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_colors = {\n",
    "    'word_lh': '#5975a4',\n",
    "    'word_nh': '#cc8963'\n",
    "}\n",
    "\n",
    "all_colors = list(all_colors.values())\n",
    "sns.set_palette(sns.color_palette(all_colors))\n",
    "\n",
    "palatal_vowel_df[\"item\"] = palatal_vowel_df[\"item\"].str.replace('_', '-') # handles don't support \"_\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(x=\"length\", y=\"vowel\",hue=\"item\" , data=palatal_vowel_df)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.set(xlabel=\"Count\", ylabel=\"Vowel\")\n",
    "\n",
    "ax.xaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "show_values_on_bars_h(ax)\n",
    "\n",
    "fig.set_size_inches(6,3.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contiguous left "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "constiguous_left_list = []\n",
    "\n",
    "dipht_lh = \"ailh|iulh|uilh|eulh|éulh|eilh|éilh|oilh|óilh|aulh|oulh\"\n",
    "dipht_nh = \"ainh|iunh|uinh|eunh|éunh|einh|éinh|oinh|óinh|aunh|ounh\"\n",
    "nasal_vowel_lh = \"nlh|nnh|ãlh\"\n",
    "nasal_vowel_nh = \"ãnh|õlh|õnh\"\n",
    "\n",
    "left_nasal_vowel_lh = word_df[word_df[\"word\"].str.contains(nasal_vowel_lh)]\n",
    "constiguous_left_list.append([\"left_nasal_vowel_lh\",len(left_nasal_vowel_lh)])\n",
    "left_dipht_lh = word_df[word_df[\"word\"].str.contains(dipht_lh)]\n",
    "left_dipht_lh = left_dipht_lh[~left_dipht_lh[\"word\"].str.contains(\"guilh|quilh|guelh|quelh\")]\n",
    "constiguous_left_list.append([\"left_dipht_lh\",len(left_dipht_lh)])\n",
    "left_rot_lh = word_df[word_df[\"word\"].str.contains(\"rlh\")]\n",
    "constiguous_left_list.append([\"left_rot_lh\",len(left_rot_lh)])\n",
    "left_lat_lh = word_df[word_df[\"word\"].str.contains(\"llh\")]\n",
    "constiguous_left_list.append([\"left_lat_lh\",len(left_lat_lh)])\n",
    "\n",
    "\n",
    "left_nasal_vowel_nh = word_df[word_df[\"word\"].str.contains(nasal_vowel_nh)]\n",
    "constiguous_left_list.append([\"left_nasal_vowel_nh\",len(left_nasal_vowel_nh)])\n",
    "left_dipht_nh = word_df[word_df[\"word\"].str.contains(dipht_nh)]\n",
    "#print(left_dipht_nh)\n",
    "left_dipht_nh = left_dipht_nh[~left_dipht_nh[\"word\"].str.contains(\"guinh|quinh|guenh|quenh\")]\n",
    "constiguous_left_list.append([\"left_dipht_nh\",len(left_dipht_nh)])\n",
    "left_rot_nh = word_df[word_df[\"word\"].str.contains(\"rnh\")]\n",
    "constiguous_left_list.append([\"left_rot_nh\",len(left_rot_nh)])\n",
    "left_lat_nh = word_df[word_df[\"word\"].str.contains(\"lnh\")]\n",
    "constiguous_left_list.append([\"left_lat_nh\",len(left_lat_nh)])\n",
    "\n",
    "constiguous_left_df = pd.DataFrame(constiguous_left_list, columns=[\"item\",\"length\"])\n",
    "constiguous_left_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"word_IPA_wikcionario_dipht_left_palatal.xlsx\", \n",
    "                        engine='xlsxwriter', \n",
    "                        options={'encoding':'utf-8'}) \n",
    "\n",
    "left_dipht_lh.to_excel(writer, index=False, sheet_name='left_dipht_lh')\n",
    "left_dipht_nh.to_excel(writer, index=False, sheet_name='left_dipht_nh')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load syllable annotated datasets\n",
    "Syllabifier from https://portulanclarin.net/workbench/lx-syllabifier/\n",
    "\n",
    "Syllabifier included in new column of word_dicio_aberto_dipht_left_palatal.xlsx file copy sheets. Phonological notes column is human corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_dipht_lh = pd.read_excel(\"word_IPA_wikcionario_dipht_left_palatal_with_syllabification.xlsx\", sheet_name=\"left_dipht_lh\")\n",
    "left_dipht_lh = len(left_dipht_lh[left_dipht_lh[\"Syllabifier\"].str.contains(\"ai•lh|ei•lh|oi•lh|ui•lh\")])\n",
    "left_dipht_nh = pd.read_excel(\"word_IPA_wikcionario_dipht_left_palatal_with_syllabification.xlsx\", sheet_name=\"left_dipht_nh\")\n",
    "left_dipht_nh = len(left_dipht_nh[left_dipht_nh[\"Syllabifier\"].str.contains(\"ai•nh|ei•nh|oi•nh|ui•nh\")])\n",
    "constiguous_left_df.loc[constiguous_left_df['item'] == 'left_dipht_lh', 'length'] = left_dipht_lh\n",
    "constiguous_left_df.loc[constiguous_left_df['item'] == 'left_dipht_nh', 'length'] = left_dipht_nh\n",
    "constiguous_left_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_colors = {\n",
    "    'word_lh': '#5975a4',\n",
    "    'word_nh': '#cc8963'\n",
    "}\n",
    "\n",
    "all_colors = list(all_colors.values())\n",
    "all_colors = list(np.repeat(all_colors,4))\n",
    "sns.set_palette(sns.color_palette(all_colors))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(x=\"length\", y=\"item\" , data=constiguous_left_df)\n",
    "show_values_on_bars_h(ax)\n",
    "fig.set_size_inches(7,3)\n",
    "ax.set(xlabel=\"Count\", ylabel=\"\")\n",
    "plt.xlim(0, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lh = word_df[word_df[\"word\"].str.contains(\"^lh\")]\n",
    "#initial_lh = len(initial_lh)\n",
    "initial_nh = word_df[word_df[\"word\"].str.contains(\"^nh\")]\n",
    "#initial_nh = len(initial_nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_list = []\n",
    "\n",
    "initial_lh = len(initial_lh)\n",
    "initial_nh = len(initial_nh)\n",
    "\n",
    "initial_list.append([\"initial_lh\",initial_lh])\n",
    "initial_list.append([\"initial_nh\",initial_nh])\n",
    "\n",
    "\n",
    "df_initial = pd.DataFrame(initial_list, columns=[\"item\",\"length\"])\n",
    "df_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load syllable annotated datasets\n",
    "Syllabifier from https://portulanclarin.net/workbench/lx-syllabifier/\n",
    "\n",
    "Syllabifier included in new column of word_dicio_aberto_lh_nh.xlsx file copy sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lh = pd.read_excel(\"word_IPA_wikcionario_lh_nh_with_syllabification.xlsx\", sheet_name=\"word_lh\")\n",
    "word_nh = pd.read_excel(\"word_IPA_wikcionario_lh_nh_with_syllabification.xlsx\", sheet_name=\"word_nh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intermedial_list = []\n",
    "\n",
    "intermedial_lh = word_lh[word_lh[\"Syllabifier\"].str.contains(\"•lh[^•]+•\")]\n",
    "not_intermedial_lh = word_lh[word_lh[\"Syllabifier\"].str.contains(\"•lh([^•])+-•se$\")]\n",
    "intermedial_lh = len(intermedial_lh) - len(not_intermedial_lh)\n",
    "\n",
    "intermedial_nh = word_nh[word_nh[\"Syllabifier\"].str.contains(\"•nh[^•]+•\")]\n",
    "not_intermedial_nh = word_nh[word_nh[\"Syllabifier\"].str.contains(\"•nh([^•])+-•se$\")]\n",
    "intermedial_nh = len(intermedial_nh) - len(not_intermedial_nh)\n",
    "\n",
    "intermedial_list.append([\"intermedial_lh\",intermedial_lh])\n",
    "intermedial_list.append([\"intermedial_nh\",intermedial_nh])\n",
    "\n",
    "df_intermedial = pd.DataFrame(intermedial_list, columns=[\"item\",\"length\"])\n",
    "df_intermedial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "\n",
    "final_lh = word_lh[word_lh[\"Syllabifier\"].str.contains(\"•lh([^•])+$|•lh([^•])+-•se$\")]\n",
    "final_lh = len(final_lh)\n",
    "\n",
    "final_nh = word_nh[word_nh[\"Syllabifier\"].str.contains(\"•nh([^•])+$|•nh([^•])+-•se$\")]\n",
    "final_nh = len(final_nh)\n",
    "\n",
    "final_list.append([\"final_lh\",final_lh])\n",
    "final_list.append([\"final_nh\",final_nh])\n",
    "\n",
    "df_final = pd.DataFrame(final_list, columns=[\"item\",\"length\"])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_initial, df_intermedial, df_final], axis= 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"length\"] = df[\"length\"]/max_total_words_length\n",
    "df[\"length\"] = df[\"length\"].round(5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_colors = {\n",
    "    'word_lh': '#5975a4',\n",
    "    'word_nh': '#cc8963'\n",
    "}\n",
    "\n",
    "all_colors = list(all_colors.values())\n",
    "all_colors = all_colors*3\n",
    "sns.set_palette(sns.color_palette(all_colors))\n",
    " \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(x=\"length\", y=\"item\" , data=df)\n",
    "\n",
    "ax.xaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "show_values_on_bars_h(ax)\n",
    "\n",
    "fig.set_size_inches(3.5,1.75)\n",
    "\n",
    "ax.set(xlabel=\"Count\", ylabel=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## double position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_nh = word_df[word_df[\"word\"].str.contains(\".*nh.*nh.*\")]\n",
    "double_nh = double_nh[~double_nh[\"word\"].str.contains(\"\\-\")]\n",
    "\n",
    "double_nh_no_inho_a = double_nh[~double_nh[\"word\"].str.contains(\"inho$|inha$\")]\n",
    "\n",
    "double_lh = word_df[word_df[\"word\"].str.contains(\".*lh.*lh.*\")]\n",
    "double_lh = double_lh[~double_lh[\"word\"].str.contains(\"\\-\")]\n",
    "\n",
    "double_list = []\n",
    "double_nh = len(double_nh)\n",
    "double_nh_no_inho_a = len(double_nh_no_inho_a)\n",
    "double_lh = len(double_lh)\n",
    "\n",
    "double_list.append([\"double_lh\",double_lh])\n",
    "double_list.append([\"double_nh\",double_nh])\n",
    "double_list.append([\"double_nh_no_inho_a\",double_nh_no_inho_a])\n",
    "\n",
    "df_double = pd.DataFrame(double_list, columns=[\"item\",\"length\"])\n",
    "df_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_colors = ['#5975a4','#cc8963','#cc8963']\n",
    "sns.set_palette(sns.color_palette(all_colors))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(x=\"length\", y=\"item\" , data=df_double)\n",
    "show_values_on_bars_reg_h(ax)\n",
    "fig.set_size_inches(10,1.3)\n",
    "ax.set(xlabel=\"Count\", ylabel=\"\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "454px",
    "left": "29px",
    "top": "111.133px",
    "width": "193.917px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
